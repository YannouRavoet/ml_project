game: phantom_ttt

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Phantom Tic Tac Toe"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["obstype"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "phantom_ttt"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 9
PolicyTensorShape() = [9]
MaxChanceOutcomes() = 0
GetParameters() = {obstype=reveal-nothing}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
InformationStateTensorShape() = [1, 214]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 214
ObservationTensorShape() = [27]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 27
MaxGameLength() = 17
ToString() = "phantom_ttt()"

# State 0
# ...
# ...
# ...
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "...\n...\n...\n"
InformationStateString(1) = "...\n...\n...\n"
InformationStateTensor(0): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "...\n...\n..."
ObservationString(1) = "...\n...\n..."
ObservationTensor(0): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8]
StringLegalActions() = ["x(0,0)", "x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)", "x(1,2)", "x(2,0)", "x(2,1)", "x(2,2)"]

# Apply action "x(0,0)"
action: 0

# State 1
# x..
# ...
# ...
IsTerminal() = False
History() = [0]
HistoryString() = "0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "x..\n...\n...\n0,0 "
InformationStateString(1) = "...\n...\n...\n"
InformationStateTensor(0): ◯◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n...\n..."
ObservationString(1) = "...\n...\n..."
ObservationTensor(0): ◯◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8]
StringLegalActions() = ["o(0,0)", "o(0,1)", "o(0,2)", "o(1,0)", "o(1,1)", "o(1,2)", "o(2,0)", "o(2,1)", "o(2,2)"]

# Apply action "o(0,1)"
action: 1

# State 2
# xo.
# ...
# ...
IsTerminal() = False
History() = [0, 1]
HistoryString() = "0 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "x..\n...\n...\n0,0 "
InformationStateString(1) = ".o.\n...\n...\n1,1 "
InformationStateTensor(0): ◯◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◉◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n...\n..."
ObservationString(1) = ".o.\n...\n..."
ObservationTensor(0): ◯◉◉◉◉◉◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◉◉◉◉◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5, 6, 7, 8]
StringLegalActions() = ["x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)", "x(1,2)", "x(2,0)", "x(2,1)", "x(2,2)"]

# Apply action "x(1,2)"
action: 5

# State 3
# xo.
# ..x
# ...
IsTerminal() = False
History() = [0, 1, 5]
HistoryString() = "0 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "x..\n..x\n...\n0,0 0,5 "
InformationStateString(1) = ".o.\n...\n...\n1,1 "
InformationStateTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◉◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\n..."
ObservationString(1) = ".o.\n...\n..."
ObservationTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯
ObservationTensor(1): ◉◯◉◉◉◉◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 7, 8]
StringLegalActions() = ["o(0,0)", "o(0,2)", "o(1,0)", "o(1,1)", "o(1,2)", "o(2,0)", "o(2,1)", "o(2,2)"]

# Apply action "o(1,2)"
action: 5

# State 4
# xo.
# ..x
# ...
IsTerminal() = False
History() = [0, 1, 5, 5]
HistoryString() = "0 1 5 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "x..\n..x\n...\n0,0 0,5 "
InformationStateString(1) = ".o.\n..x\n...\n1,1 1,5 "
InformationStateTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◯◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\n..."
ObservationString(1) = ".o.\n..x\n..."
ObservationTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯
ObservationTensor(1): ◉◯◉◉◉◯◉◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 6, 7, 8]
StringLegalActions() = ["o(0,0)", "o(0,2)", "o(1,0)", "o(1,1)", "o(2,0)", "o(2,1)", "o(2,2)"]

# Apply action "o(2,0)"
action: 6

# State 5
# xo.
# ..x
# o..
IsTerminal() = False
History() = [0, 1, 5, 5, 6]
HistoryString() = "0 1 5 5 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "x..\n..x\n...\n0,0 0,5 "
InformationStateString(1) = ".o.\n..x\no..\n1,1 1,5 1,6 "
InformationStateTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\n..."
ObservationString(1) = ".o.\n..x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◉◉◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯
ObservationTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 6, 7, 8]
StringLegalActions() = ["x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)", "x(2,0)", "x(2,1)", "x(2,2)"]

# Apply action "x(2,0)"
action: 6

# State 6
# xo.
# ..x
# o..
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6]
HistoryString() = "0 1 5 5 6 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "x..\n..x\no..\n0,0 0,5 0,6 "
InformationStateString(1) = ".o.\n..x\no..\n1,1 1,5 1,6 "
InformationStateTensor(0): ◯◉◉◉◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\no.."
ObservationString(1) = ".o.\n..x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◯
ObservationTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 7, 8]
StringLegalActions() = ["x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)", "x(2,1)", "x(2,2)"]

# Apply action "x(2,2)"
action: 8

# State 7
# xo.
# ..x
# o.x
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8]
HistoryString() = "0 1 5 5 6 6 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "x..\n..x\no.x\n0,0 0,5 0,6 0,8 "
InformationStateString(1) = ".o.\n..x\no..\n1,1 1,5 1,6 "
InformationStateTensor(0): ◯◉◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\no.x"
ObservationString(1) = ".o.\n..x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◉
ObservationTensor(1): ◉◯◉◉◉◯◯◉◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 7, 8]
StringLegalActions() = ["o(0,0)", "o(0,2)", "o(1,0)", "o(1,1)", "o(2,1)", "o(2,2)"]

# Apply action "o(1,0)"
action: 3

# State 8
# xo.
# o.x
# o.x
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3]
HistoryString() = "0 1 5 5 6 6 8 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "x..\n..x\no.x\n0,0 0,5 0,6 0,8 "
InformationStateString(1) = ".o.\no.x\no..\n1,1 1,5 1,6 1,3 "
InformationStateTensor(0): ◯◉◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◯◉◯◯◉◉◯◉◯◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\no.x"
ObservationString(1) = ".o.\no.x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◯◉
ObservationTensor(1): ◉◯◉◯◉◯◯◉◉◯◉◯◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 7]
StringLegalActions() = ["x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)", "x(2,1)"]

# Apply action "x(2,1)"
action: 7

# State 9
# xo.
# o.x
# oxx
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7]
HistoryString() = "0 1 5 5 6 6 8 3 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "x..\n..x\noxx\n0,0 0,5 0,6 0,8 0,7 "
InformationStateString(1) = ".o.\no.x\no..\n1,1 1,5 1,6 1,3 "
InformationStateTensor(0): ◯◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◉◯◉◯◯◉◉◯◉◯◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\noxx"
ObservationString(1) = ".o.\no.x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉
ObservationTensor(1): ◉◯◉◯◉◯◯◉◉◯◉◯◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 4, 7, 8]
StringLegalActions() = ["o(0,0)", "o(0,2)", "o(1,1)", "o(2,1)", "o(2,2)"]

# Apply action "o(0,2)"
action: 2

# State 10
# xoo
# o.x
# oxx
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7, 2]
HistoryString() = "0 1 5 5 6 6 8 3 7 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "x..\n..x\noxx\n0,0 0,5 0,6 0,8 0,7 "
InformationStateString(1) = ".oo\no.x\no..\n1,1 1,5 1,6 1,3 1,2 "
InformationStateTensor(0): ◯◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "x..\n..x\noxx"
ObservationString(1) = ".oo\no.x\no.."
ObservationTensor(0): ◯◉◉◉◉◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉
ObservationTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4]
StringLegalActions() = ["x(0,1)", "x(0,2)", "x(1,0)", "x(1,1)"]

# Apply action "x(0,1)"
action: 1

# State 11
# xoo
# o.x
# oxx
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7, 2, 1]
HistoryString() = "0 1 5 5 6 6 8 3 7 2 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "xo.\n..x\noxx\n0,0 0,5 0,6 0,8 0,7 0,1 "
InformationStateString(1) = ".oo\no.x\no..\n1,1 1,5 1,6 1,3 1,2 "
InformationStateTensor(0): ◯◯◉◉◉◯◯◯◯◯◉◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "xo.\n..x\noxx"
ObservationString(1) = ".oo\no.x\no.."
ObservationTensor(0): ◯◯◉◉◉◯◯◯◯◯◉◯◯◯◯◉◯◯◉◯◯◯◯◉◯◉◉
ObservationTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 3, 4]
StringLegalActions() = ["x(0,2)", "x(1,0)", "x(1,1)"]

# Apply action "x(1,0)"
action: 3

# State 12
# xoo
# o.x
# oxx
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7, 2, 1, 3]
HistoryString() = "0 1 5 5 6 6 8 3 7 2 1 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "xo.\no.x\noxx\n0,0 0,5 0,6 0,8 0,7 0,1 0,3 "
InformationStateString(1) = ".oo\no.x\no..\n1,1 1,5 1,6 1,3 1,2 "
InformationStateTensor(0): ◯◯◉◯◉◯◯◯◯◯◉◯◉◯◯◉◯◯◉◯◯◯◯◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "xo.\no.x\noxx"
ObservationString(1) = ".oo\no.x\no.."
ObservationTensor(0): ◯◯◉◯◉◯◯◯◯◯◉◯◉◯◯◉◯◯◉◯◯◯◯◉◯◉◉
ObservationTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4]
StringLegalActions() = ["x(0,2)", "x(1,1)"]

# Apply action "x(0,2)"
action: 2

# State 13
# xoo
# o.x
# oxx
IsTerminal() = False
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7, 2, 1, 3, 2]
HistoryString() = "0 1 5 5 6 6 8 3 7 2 1 3 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "xoo\no.x\noxx\n0,0 0,5 0,6 0,8 0,7 0,1 0,3 0,2 "
InformationStateString(1) = ".oo\no.x\no..\n1,1 1,5 1,6 1,3 1,2 "
InformationStateTensor(0): ◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◯◯◉◯◯◯◯◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "xoo\no.x\noxx"
ObservationString(1) = ".oo\no.x\no.."
ObservationTensor(0): ◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◯◯◉◯◯◯◯◉◯◉◉
ObservationTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4]
StringLegalActions() = ["x(1,1)"]

# Apply action "x(1,1)"
action: 4

# State 14
# xoo
# oxx
# oxx
IsTerminal() = True
History() = [0, 1, 5, 5, 6, 6, 8, 3, 7, 2, 1, 3, 2, 4]
HistoryString() = "0 1 5 5 6 6 8 3 7 2 1 3 2 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "xoo\noxx\noxx\n0,0 0,5 0,6 0,8 0,7 0,1 0,3 0,2 0,4 "
InformationStateString(1) = ".oo\no.x\no..\n1,1 1,5 1,6 1,3 1,2 "
InformationStateTensor(0): ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◯◉◯◯◉◯◯◯◉◉◯◉◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "xoo\noxx\noxx"
ObservationString(1) = ".oo\no.x\no.."
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◯◉◯◯◉◯◯◯◉◉◯◉◉
ObservationTensor(1): ◉◯◯◯◉◯◯◉◉◯◉◉◉◯◯◉◯◯◯◯◯◯◯◉◯◯◯
Rewards() = [1.0, -1.0]
Returns() = [1.0, -1.0]
