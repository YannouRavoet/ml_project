game: y(board_size=9)

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Y Connection Game"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["ansi_color_output", "board_size"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "y"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 81
PolicyTensorShape() = [81]
MaxChanceOutcomes() = 0
GetParameters() = {ansi_color_output=False,board_size=9}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 9, 9]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 243
MaxGameLength() = 45
ToString() = "y(board_size=9)"

# State 0
#   a b c d e f g h i
#  1 . . . . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . .
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "  a b c d e f g h i\n 1 . . . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . . . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "b1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "f4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "b1"
action: 1

# State 1
#   a b c d e f g h i
#  1 .[O]. . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . .
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1]
HistoryString() = "1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1"
InformationStateString(1) = "1"
ObservationString(0) = "  a b c d e f g h i\n 1 .[O]. . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 .[O]. . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "f4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "f4"
action: 32

# State 2
#   a b c d e f g h i
#  1 . O . . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . .[@]
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32]
HistoryString() = "1 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32"
InformationStateString(1) = "1 32"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . .[@]\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . .[@]\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "g1"
action: 6

# State 3
#   a b c d e f g h i
#  1 . O . . . .[O]. .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6]
HistoryString() = "1 32 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6"
InformationStateString(1) = "1 32 6"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . .[O]. .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . .[O]. .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◉◯◯  ◉◯◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "f1"
action: 5

# State 4
#   a b c d e f g h i
#  1 . O . . .[@]O . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5]
HistoryString() = "1 32 6 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5"
InformationStateString(1) = "1 32 6 5"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . .[@]O . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . .[@]O . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◯◯  ◉◯◉◉◉◯◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "h1"
action: 7

# State 5
#   a b c d e f g h i
#  1 . O . . . @ O[O].
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7]
HistoryString() = "1 32 6 5 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7"
InformationStateString(1) = "1 32 6 5 7"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O[O].\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O[O].\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "c2"
action: 11

# State 6
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . .[@]. . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11]
HistoryString() = "1 32 6 5 7 11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11"
InformationStateString(1) = "1 32 6 5 7 11"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . .[@]. . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . .[@]. . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "a3"
action: 18

# State 7
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . . @ . . . . .
#    3[O]. . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18]
HistoryString() = "1 32 6 5 7 11 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18"
InformationStateString(1) = "1 32 6 5 7 11 18"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3[O]. . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3[O]. . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "b8"
action: 64

# State 8
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . . @ . . . . .
#    3 O . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 .[@]
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64]
HistoryString() = "1 32 6 5 7 11 18 64"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64"
InformationStateString(1) = "1 32 6 5 7 11 18 64"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 .[@]\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 .[@]\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "g3"
action: 24

# State 9
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . . @ . . . . .
#    3 O . . . . .[O]
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24]
HistoryString() = "1 32 6 5 7 11 18 64 24"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . .[O]\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . .[O]\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "b5"
action: 37

# State 10
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . . @ . . . . .
#    3 O . . . . . O
#     4 . . . . . @
#      5 .[@]. . .
#       6 . . . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37]
HistoryString() = "1 32 6 5 7 11 18 64 24 37"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . O\n    4 . . . . . @\n     5 .[@]. . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . O\n    4 . . . . . @\n     5 .[@]. . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 36, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "d4", "e4", "a5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "d4"
action: 30

# State 11
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 . . @ . . . . .
#    3 O . . . . . O
#     4 . . .[O]. @
#      5 . @ . . .
#       6 . . . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . O\n    4 . . .[O]. @\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 . . @ . . . . .\n   3 O . . . . . O\n    4 . . .[O]. @\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯◯  ◉◉◉◯◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 31, 36, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "e4", "a5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "a2"
action: 9

# State 12
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2[@]. @ . . . . .
#    3 O . . . . . O
#     4 . . . O . @
#      5 . @ . . .
#       6 . . . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2[@]. @ . . . . .\n   3 O . . . . . O\n    4 . . . O . @\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2[@]. @ . . . . .\n   3 O . . . . . O\n    4 . . . O . @\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯◯  ◉◉◉◯◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 31, 36, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "e4", "a5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "e4"
action: 31

# State 13
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . . . O[O]@
#      5 . @ . . .
#       6 . . . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O[O]@\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O[O]@\n     5 . @ . . .\n      6 . . . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◉◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 36, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "a5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "b6"
action: 46

# State 14
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . . . O O @
#      5 . @ . . .
#       6 .[@]. .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5 . @ . . .\n      6 .[@]. .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5 . @ . . .\n      6 .[@]. .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◉◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 36, 38, 39, 40, 45, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "a5", "c5", "d5", "e5", "a6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "a5"
action: 36

# State 15
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . . . O O @
#      5[O]@ . . .
#       6 . @ . .
#        7 . . .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5[O]@ . . .\n      6 . @ . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5[O]@ . . .\n      6 . @ . .\n       7 . . .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◉◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 38, 39, 40, 45, 47, 48, 54, 55, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "c5", "d5", "e5", "a6", "c6", "d6", "a7", "b7", "c7", "a8", "a9"]

# Apply action "b7"
action: 55

# State 16
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . . . O O @
#      5 O @ . . .
#       6 . @ . .
#        7 .[@].
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5 O @ . . .\n      6 . @ . .\n       7 .[@].\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . . . O O @\n     5 O @ . . .\n      6 . @ . .\n       7 .[@].\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◉◉◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 38, 39, 40, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "b4", "c4", "c5", "d5", "e5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "b4"
action: 28

# State 17
#   a b c d e f g h i
#  1 . O . . . @ O O .
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 .[O]. O O @
#      5 O @ . . .
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 .[O]. O O @\n     5 O @ . . .\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O .\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 .[O]. O O @\n     5 O @ . . .\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 29, 38, 39, 40, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "e5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "i1"
action: 8

# State 18
#   a b c d e f g h i
#  1 . O . . . @ O O[@]
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . . .
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O[@]\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . .\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O[@]\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . .\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◯
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 29, 38, 39, 40, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "e5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "e5"
action: 40

# State 19
#   a b c d e f g h i
#  1 . O . . . @ O O @
#   2 @ . @ . . . . .
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . .[O]
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . .[O]\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . . .\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . .[O]\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◯
◉◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "b2", "d2", "e2", "f2", "g2", "h2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "h2"
action: 16

# State 20
#   a b c d e f g h i
#  1 . O . . . @ O O @
#   2 @ . @ . . . .[@]
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . .[@]\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . .[@]\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "e1"
action: 4

# State 21
#   a b c d e f g h i
#  1 . O . .[O]@ O O @
#   2 @ . @ . . . . @
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . .[O]@ O O @\n  2 @ . @ . . . . @\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . .[O]@ O O @\n  2 @ . @ . . . . @\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "e3"
action: 22

# State 22
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ . . . . @
#    3 O . . .[@]. O
#     4 . O . O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . .[@]. O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . .[@]. O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◉◯◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "c4"
action: 29

# State 23
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ . . . . @
#    3 O . . . @ . O
#     4 . O[O]O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O[O]O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O[O]O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◉◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 23, 27, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "a9"
action: 72

# State 24
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ . . . . @
#    3 O . . . @ . O
#     4 . O O O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9[@]
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9[@]\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9[@]\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◉◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 23, 27, 38, 39, 45, 47, 48, 54, 56, 63]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8"]

# Apply action "a8"
action: 63

# State 25
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ . . . . @
#    3 O . . . @ . O
#     4 . O O O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8[O]@
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8[O]@\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ . . . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8[O]@\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◉◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 23, 27, 38, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "d2"
action: 12

# State 26
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @[@]. . . @
#    3 O . . . @ . O
#     4 . O O O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @[@]. . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @[@]. . . @\n   3 O . . . @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◉◯  ◯◉◯◯◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◉◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◯◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 14, 15, 19, 20, 21, 23, 27, 38, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "f2", "g2", "b3", "c3", "d3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "d3"
action: 21

# State 27
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ . . . @
#    3 O . .[O]@ . O
#     4 . O O O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . . @\n   3 O . .[O]@ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . . @\n   3 O . .[O]@ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◉◯  ◯◉◯◯◉◉◉◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◯◉◉◉◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 14, 15, 19, 20, 23, 27, 38, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "f2", "g2", "b3", "c3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "g2"
action: 15

# State 28
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ . .[@]@
#    3 O . . O @ . O
#     4 . O O O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . .[@]@\n   3 O . . O @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . .[@]@\n   3 O . . O @ . O\n    4 . O O O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◉◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◯◉◉◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 14, 19, 20, 23, 27, 38, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "f2", "b3", "c3", "f3", "a4", "c5", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "c5"
action: 38

# State 29
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ . . @ @
#    3 O . . O @ . O
#     4 . O O O O @
#      5 O @[O]. O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . @ @\n   3 O . . O @ . O\n    4 . O O O O @\n     5 O @[O]. O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . @ @\n   3 O . . O @ . O\n    4 . O O O O @\n     5 O @[O]. O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◉◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◯◉◉◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 14, 19, 20, 23, 27, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "f2", "b3", "c3", "f3", "a4", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "a4"
action: 27

# State 30
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ . . @ @
#    3 O . . O @ . O
#     4[@]O O O O @
#      5 O @ O . O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . @ @\n   3 O . . O @ . O\n    4[@]O O O O @\n     5 O @ O . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . . @ @\n   3 O . . O @ . O\n    4[@]O O O O @\n     5 O @ O . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◉◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◯◉◉◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 14, 19, 20, 23, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "f2", "b3", "c3", "f3", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "f2"
action: 14

# State 31
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ .[O]@ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 . @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ .[O]@ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ .[O]@ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 . @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 19, 20, 23, 39, 45, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "b3", "c3", "f3", "d5", "a6", "c6", "d6", "a7", "c7"]

# Apply action "a6"
action: 45

# State 32
#   a b c d e f g h i
#  1 . O . . O @ O O @
#   2 @ . @ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6[@]@ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6[@]@ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6[@]@ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 13, 19, 20, 23, 39, 47, 48, 54, 56]
StringLegalActions() = ["a1", "c1", "d1", "b2", "e2", "b3", "c3", "f3", "d5", "c6", "d6", "a7", "c7"]

# Apply action "c1"
action: 2

# State 33
#   a b c d e f g h i
#  1 . O[O]. O @ O O @
#   2 @ . @ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7 . @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2"
ObservationString(0) = "  a b c d e f g h i\n 1 . O[O]. O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O[O]. O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 . @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◯◉◯◉◉◯  ◉◯◯◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 10, 13, 19, 20, 23, 39, 47, 48, 54, 56]
StringLegalActions() = ["a1", "d1", "b2", "e2", "b3", "c3", "f3", "d5", "c6", "d6", "a7", "c7"]

# Apply action "a7"
action: 54

# State 34
#   a b c d e f g h i
#  1 . O O . O @ O O @
#   2 @ . @ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7[@]@ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O . O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7[@]@ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O . O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7[@]@ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◯◉◯◉◉◯  ◉◯◯◉◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 10, 13, 19, 20, 23, 39, 47, 48, 56]
StringLegalActions() = ["a1", "d1", "b2", "e2", "b3", "c3", "f3", "d5", "c6", "d6", "c7"]

# Apply action "d1"
action: 3

# State 35
#   a b c d e f g h i
#  1 . O O[O]O @ O O @
#   2 @ . @ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7 @ @ .
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O[O]O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ .\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O[O]O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ .\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 10, 13, 19, 20, 23, 39, 47, 48, 56]
StringLegalActions() = ["a1", "b2", "e2", "b3", "c3", "f3", "d5", "c6", "d6", "c7"]

# Apply action "c7"
action: 56

# State 36
#   a b c d e f g h i
#  1 . O O O O @ O O @
#   2 @ . @ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7 @ @[@]
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @[@]\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ . @ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @[@]\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◯◉◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 10, 13, 19, 20, 23, 39, 47, 48]
StringLegalActions() = ["a1", "b2", "e2", "b3", "c3", "f3", "d5", "c6", "d6"]

# Apply action "b2"
action: 10

# State 37
#   a b c d e f g h i
#  1 . O O O O @ O O @
#   2 @[O]@ @ . O @ @
#    3 O . . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @[O]@ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @[O]@ @ . O @ @\n   3 O . . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯◯  ◯◉◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◉◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 13, 19, 20, 23, 39, 47, 48]
StringLegalActions() = ["a1", "e2", "b3", "c3", "f3", "d5", "c6", "d6"]

# Apply action "b3"
action: 19

# State 38
#   a b c d e f g h i
#  1 . O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O[@]. O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ . .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O[@]. O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O[@]. O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ . .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◯◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 13, 20, 23, 39, 47, 48]
StringLegalActions() = ["a1", "e2", "c3", "f3", "d5", "c6", "d6"]

# Apply action "c6"
action: 47

# State 39
#   a b c d e f g h i
#  1 . O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O @ . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @[O].
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47"
ObservationString(0) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @[O].\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @[O].\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◯◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 13, 20, 23, 39, 48]
StringLegalActions() = ["a1", "e2", "c3", "f3", "d5", "d6"]

# Apply action "a1"
action: 0

# State 40
#   a b c d e f g h i
#  1[@]O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O @ . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ O .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0"
ObservationString(0) = "  a b c d e f g h i\n 1[@]O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1[@]O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◉◯◯◉  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◯◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [13, 20, 23, 39, 48]
StringLegalActions() = ["e2", "c3", "f3", "d5", "d6"]

# Apply action "f3"
action: 23

# State 41
#   a b c d e f g h i
#  1 @ O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O @ . O @[O]O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ O .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = True
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0, 23]
HistoryString() = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0 23"
InformationStateString(1) = "1 32 6 5 7 11 18 64 24 37 30 9 31 46 36 55 28 8 40 16 4 22 29 72 63 12 21 15 38 27 14 45 2 54 3 56 10 19 47 0 23"
ObservationString(0) = "  a b c d e f g h i\n 1 @ O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @[O]O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 @ O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @[O]O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◉◯◯◉  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◉◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◉◉◯◯  ◯◯◉◯◯◯◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [1.0, -1.0]
Returns() = [1.0, -1.0]
